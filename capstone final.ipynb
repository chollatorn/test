{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction and Business Problem**\n",
    "\n",
    "**Introduction:**\n",
    "\n",
    "The city of Hoboken, NJ is relatively small at ~1 square mile but it is packed with restaurants, night life and amazing people. For people that are new to Hoboken, despite its small geographic size, it can be daunting to figure out what restaurants are worth going to and where they are. For people that used to live in Hoboken or are visiting Hoboken, how do you know what the best places are to get something to eat?\n",
    "Business Problem:\n",
    "\n",
    "For this project, I am going to put on my entrepreneur hat and create a simple guide on where to eat based on Foursquare likes, restaurant category and geographic location data for restaurants in Hoboken. I will then cluster these restaurants based on their similarities so that a user can easily determine what type of restaurants are best to eat at based on Foursquare user feedback.\n",
    "\n",
    "**Data Required**\n",
    "\n",
    "For this assignment, I will be utilizing the Foursquare API to pull the following location data on restaurants in Hoboken, NJ:\n",
    "\n",
    "Venue Name\n",
    "Venue ID\n",
    "Venue Location\n",
    "Venue Category\n",
    "Count of Likes\n",
    "Data Acquisition Approach\n",
    "To acquire the data mentioned above, I will need to do the following:\n",
    "\n",
    "Get geolocator lat and long coordinates for Hoboken, NJ\n",
    "Use Foursquare API to get a list of all venues in Hoboken\n",
    "Get venue name, venue ID, location, category, and likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # library to handle data in a vectorized manner\n",
    "\n",
    "import pandas as pd # library for data analsysis\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import json # library to handle JSON files\n",
    "\n",
    "!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\n",
    "#from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
    "\n",
    "import requests # library to handle requests\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
    "\n",
    "# Matplotlib and associated plotting modules\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# import k-means from clustering stage\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\n",
    "#import folium # map rendering library\n",
    "\n",
    "#import beautiful soup\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding the geo data for Hoboken**\n",
    "\n",
    "Let's find the geographic data for Hoboken so we can pull it from FourSquare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Nominatim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-9bbd8fdc5c5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0maddress\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Hoboken, New Jersey'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgeolocator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNominatim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mlocation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeolocator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeocode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlatitude\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Nominatim' is not defined"
     ]
    }
   ],
   "source": [
    "address = 'Hoboken, New Jersey'\n",
    "\n",
    "geolocator = Nominatim()\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "print('The geograpical coordinate of Hoboken are {}, {}.'.format(latitude, longitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FourSquare Part 1**\n",
    "\n",
    "Entering in our information into the Foursquare API to access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CLIENT_ID = '' # your Foursquare ID\n",
    "CLIENT_SECRET = '' # your Foursquare Secret\n",
    "VERSION = '20180605' # Foursquare API version\n",
    "\n",
    "print('Your credentails:')\n",
    "print('CLIENT_ID: ' + CLIENT_ID)\n",
    "print('CLIENT_SECRET:' + CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FourSquare Part 2**\n",
    "\n",
    "Creating a URL for all of the venues in Hoboken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT = 100 # limit of number of venues returned by Foursquare API\n",
    "radius = 500 # define radius\n",
    "\n",
    "# create URL\n",
    "url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "    CLIENT_ID, \n",
    "    CLIENT_SECRET, \n",
    "    VERSION, \n",
    "    latitude, \n",
    "    longitude, \n",
    "    radius, \n",
    "    LIMIT)\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FourSquare Part 3**\n",
    "\n",
    "Pulling the JSON for the URL of venues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = requests.get(url).json()\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Foursquare Part 4**\n",
    "\n",
    "Now we start pulling the data from Foursquare into a dataframe so we can manipulate and use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_type(row):\n",
    "    try:\n",
    "        categories_list = row['categories']\n",
    "    except:\n",
    "        categories_list = row['venue.categories']\n",
    "        \n",
    "    if len(categories_list) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return categories_list[0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pull the actual data from the Foursquare API\n",
    "\n",
    "venues = results['response']['groups'][0]['items']\n",
    "nearby_venues = json_normalize(venues)\n",
    "filtered_columns = ['venue.name', 'venue.id', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\n",
    "nearby_venues\n",
    "nearby_venues =nearby_venues.loc[:, filtered_columns]\n",
    "\n",
    "# filter the category for each row\n",
    "nearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n",
    "\n",
    "nearby_venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix the column names so they look relatively normal\n",
    "\n",
    "nearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n",
    "\n",
    "nearby_venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a list of unique categories from the API so we can see what may or may not fit for restaurants\n",
    "\n",
    "nearby_venues['categories'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of categorie to remove from our dataframe because they are not restaurants\n",
    "# I am sure there is a function that can be written to do this at scale but since it was a small list, I did it manually\n",
    "\n",
    "removal_list = ['Gym / Fitness Center', 'Bakery', 'Park', \"Women's Store\", 'Sporting Goods Shop', 'Dog Run', 'Gaming Cafe',\n",
    "               'Optical Shop', 'Yoga Studio', 'Pet Store', 'Shoe Repair', 'Jewelry Store', 'Record Shop', 'Juice Bar', \n",
    "               'Cosmetics Shop', 'Business Service', 'Salon / Barbershop', 'Liquor Store', 'Grocery Store', 'Stationery Store',\n",
    "               'Pilates Studio', 'Dessert Shop', 'Bookstore', 'Concert Hall', 'Video Game Store', 'Pharmacy', 'Mobile Phone Shop',\n",
    "               'Deli / Bodega']\n",
    "\n",
    "nearby_venues2 = nearby_venues.copy()\n",
    "\n",
    "\n",
    "#getting a clear dataframe of just restaurants\n",
    "nearby_venues2 = nearby_venues2[~nearby_venues2['categories'].isin(removal_list)]\n",
    "nearby_venues2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's get a list of venues\n",
    "\n",
    "venue_id_list = nearby_venues2['id'].tolist()\n",
    "venue_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#set up to pull the likes from the API based on venue ID\n",
    "\n",
    "url_list = []\n",
    "like_list = []\n",
    "json_list = []\n",
    "\n",
    "for i in venue_id_list:\n",
    "    venue_url = 'https://api.foursquare.com/v2/venues/{}/likes?client_id={}&client_secret={}&v={}'.format(i, CLIENT_ID, CLIENT_SECRET, VERSION)\n",
    "    url_list.append(venue_url)\n",
    "for link in url_list:\n",
    "    result = requests.get(link).json()\n",
    "    likes = result['response']['likes']['count']\n",
    "    like_list.append(likes)\n",
    "print(like_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#double check that we did not lose any venues based on if likes were available\n",
    "\n",
    "print(len(like_list))\n",
    "print(len(venue_id_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Prep Intro**\n",
    "\n",
    "The thought process behind this is that likes are a proxy for quality. The more likes there are, the better the restaurant is. This might be incorrect but API call issues (how many I can use for free) holds me back from getting price / rating data. I will then bin this data into a quality categorical variables so we can cluster appropriately.\n",
    "\n",
    "I am also going to create new categorical variables for the restaurants to better group them based on type of cuisine. This way you can look for good mexican food or now what type of food might be best to eat in Hoboken if you are new to the area.\n",
    "\n",
    "**Data Prep Part 1**\n",
    "\n",
    "Now let's start prepping our data for clustering. This will include combining data from different lists, creating new categorical data to be used, binning data and then encoding the data for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's make a copy of our initial dataframe just in case anything goes wrong\n",
    "\n",
    "hoboken_venues = nearby_venues2.copy()\n",
    "hoboken_venues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Prep Part 2**\n",
    "\n",
    "Let's combine our list of likes into our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in the list of likes\n",
    "\n",
    "hoboken_venues['total likes'] = like_list\n",
    "hoboken_venues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Prep 3**\n",
    "\n",
    "Let's look at our like data to set bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's bin total likes\n",
    "\n",
    "print(hoboken_venues['total likes'].max())\n",
    "print(hoboken_venues['total likes'].min())\n",
    "print(hoboken_venues['total likes'].median())\n",
    "print(hoboken_venues['total likes'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's visualize our total likes based on a histogram\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "hoboken_venues['total likes'].hist(bins=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the bins we want to use?\n",
    "\n",
    "print(np.percentile(hoboken_venues['total likes'], 25))\n",
    "print(np.percentile(hoboken_venues['total likes'], 50))\n",
    "print(np.percentile(hoboken_venues['total likes'], 75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have our bin values so let's set them to the appropriate values\n",
    "# less than 24, 24-45, 45-76, 76>\n",
    "# poor, below avg, abv avg, great\n",
    "\n",
    "poor = hoboken_venues['total likes']<=24\n",
    "below_avg = hoboken_venues[(hoboken_venues['total likes']>24) & (hoboken_venues['total likes']<=45)]\n",
    "abv_avg = hoboken_venues[(hoboken_venues['total likes']>45) & (hoboken_venues['total likes']<=76)]\n",
    "great = hoboken_venues['total likes']>76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's set up a function that will re-categorize our restaurants based on likes\n",
    "\n",
    "def conditions(s):\n",
    "    if s['total likes']<=24:\n",
    "        return 'poor'\n",
    "    if s['total likes']<=45:\n",
    "        return 'below avg'\n",
    "    if s['total likes']<=76:\n",
    "        return 'avg avg'\n",
    "    if s['total likes']>76:\n",
    "        return 'great'\n",
    "\n",
    "hoboken_venues['total likes_cat']=hoboken_venues.apply(conditions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoboken_venues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's star the process for re-categorizing the categories\n",
    "\n",
    "hoboken_venues['categories'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create our new categories and create a function to apply those to our existing data\n",
    "bars = ['Pub', 'Cocktail Bar', 'Bar', 'Dive Bar', 'Sports Bar']\n",
    "other = ['Bagel Shop', 'Tea Room', 'Donut Shop', 'Coffee Shop', 'Bubble Tea Shop', 'Sandwich Place', 'Boutique', 'Ice Cream Shop']\n",
    "euro_asia_indian_food = ['Falafel Restaurant', 'Korean Restaurant','Sushi Restaurant', 'Indian Restaurant', 'Japanese Restaurant', 'Poke Place', 'Thai Restaurant', 'Vietnamese Restaurant']\n",
    "mex_southam_food = ['Cuban Restaurant', 'Mexican Restaurant', 'South American Restaurant', 'Latin American Restaurant']\n",
    "american_food = ['Burger Joint', 'Restaurant', 'American Restaurant']\n",
    "italian_food = ['Italian Restaurant', 'Seafood Restaurant', 'Pizza Place']\n",
    "\n",
    "def conditions2(s):\n",
    "    if s['categories'] in bars:\n",
    "        return 'bars'\n",
    "    if s['categories'] in other:\n",
    "        return 'other'\n",
    "    if s['categories'] in euro_asia_indian_food:\n",
    "        return 'euro asia indian food'\n",
    "    if s['categories'] in mex_southam_food:\n",
    "        return 'mex southam food'\n",
    "    if s['categories'] in american_food:\n",
    "        return 'american food'\n",
    "    if s['categories'] in italian_food:\n",
    "        return 'italian food'\n",
    "\n",
    "hoboken_venues['categories_new']=hoboken_venues.apply(conditions2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoboken_venues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Prep Part 4**\n",
    "\n",
    "Now let's create dummy variables for our total likes and categories so we can cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "hoboken_onehot = pd.get_dummies(hoboken_venues[['categories_new', 'total likes_cat']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# add neighborhood column back to dataframe\n",
    "hoboken_onehot['Name'] = hoboken_venues['name'] \n",
    "\n",
    "# move neighborhood column to the first column\n",
    "fixed_columns = [hoboken_onehot.columns[-1]] + list(hoboken_onehot.columns[:-1])\n",
    "hoboken_onehot = hoboken_onehot[fixed_columns]\n",
    "\n",
    "hoboken_onehot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clustering Part 1**\n",
    "\n",
    "Now let's run our k-means clustering algo to get our labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = hoboken_onehot.drop('Name', axis=1)\n",
    "\n",
    "k_clusters = 4\n",
    "\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters=k_clusters, random_state=0).fit(cluster_df)\n",
    "\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clustering Part 2**\n",
    "\n",
    "Let's add our cluster labels back into our original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoboken_venues['label'] = kmeans.labels_\n",
    "hoboken_venues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clustering Part 3**\n",
    "\n",
    "Now let's visualize what our clusters look like for Hoboken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'folium' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e00884c2e113>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmap_clusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfolium\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlongitude\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzoom_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# set color scheme for the clusters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_clusters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'folium' is not defined"
     ]
    }
   ],
   "source": [
    "map_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(k_clusters)\n",
    "ys = [i+x+(i*x)**2 for i in range(k_clusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(hoboken_venues['lat'], hoboken_venues['lng'], hoboken_venues['name'], hoboken_venues['label']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "       \n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clustering Part 4**\n",
    "\n",
    "Now let's see what is in each of our clusters\n",
    "\n",
    "**Cluster 1**\n",
    "\n",
    "characteristics\n",
    "Poor quality food\n",
    "Mostly Italian food or other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoboken_venues.loc[hoboken_venues['label']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cluster 2**\n",
    "\n",
    "characteristics\n",
    "below average quality food\n",
    "Mostly Europe / Asia inspired food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoboken_venues.loc[hoboken_venues['label']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cluster 3**\n",
    "\n",
    "characteristics\n",
    "High quality food\n",
    "Mostly Mexican and South American food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoboken_venues.loc[hoboken_venues['label']==2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cluster 4**\n",
    "\n",
    "characteristics\n",
    "Above average quality food\n",
    "Mostly Bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoboken_venues.loc[hoboken_venues['label']==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
